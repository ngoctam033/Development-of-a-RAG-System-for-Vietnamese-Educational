# ğŸ“ˆ Má»™t sá»‘ bá»• sung (so vá»›i `Development-of-a-RAG-System-for-Vietnamese-Educational-main`)

> Pháº¡m vi: **Backend + RAG pipeline** (hiá»‡u suáº¥t, Ä‘á»™ chÃ­nh xÃ¡c, logic)

## ğŸ“‚ Cáº¥u trÃºc & thÃ nh pháº§n má»›i

- ThÃªm **Hybrid Retrieval layer**:
  - `rag_pipeline/indexes/faiss_store.py` â€” FAISS index (dense).
  - `rag_pipeline/retrieval/bm25_store.py` â€” BM25 (sparse).
  - `rag_pipeline/retrieval/retriever.py` â€” há»£p nháº¥t Ä‘iá»ƒm **dense + sparse + rerank**.
  - `rag_pipeline/retrieval/keyword_extractor.py` â€” trÃ­ch xuáº¥t keyword há»— trá»£ truy há»“i.
- Bá»• sung script tiá»‡n Ã­ch:
  - `reindex_faiss.py` â€” (re)build FAISS nhanh tá»« corpus.
- Tá»‘i Æ°u module hiá»‡n cÃ³:
  - `rag_pipeline/generation/llm.py` â€” Ä‘iá»u phá»‘i LLM + retry + safety.
  - `rag_pipeline/vectorization/embedder.py` â€” chuyá»ƒn sang logger máº·c Ä‘á»‹nh, tÆ°Æ¡ng thÃ­ch cáº¥u hÃ¬nh má»›i.
  - `rag_pipeline/processing/chunking.py` â€” thá»‘ng nháº¥t logger, giá»¯ nguyÃªn API.

## âš™ï¸ Pipeline RAG (logic & tham sá»‘)

- ThÃªm file cáº¥u hÃ¬nh rÃµ rÃ ng:
  - `config/models_config.py`
    - `EMBEDDING_MODEL = "BAAI/bge-m3"` _(Ä‘a ngÃ´n ngá»¯, ráº¥t há»£p tiáº¿ng Viá»‡t)_.
    - `RERANKER_MODEL = "cross-encoder/ms-marco-MiniLM-L-6-v2"`.
  - `config/pipeline_config.py`
    ```python
    CHUNK_SIZE = 800
    CHUNK_OVERLAP = 200
    TOP_K_RECALL = 50         # kÃ©o rá»™ng trÆ°á»›c khi rerank
    TOP_K_FINAL = 8           # Ä‘Æ°a vÃ o LLM sau rerank
    SIMILARITY_THRESHOLD = 0.55
    HYBRID_ALPHA = 0.60       # Æ°u tiÃªn dense hÆ¡n BM25
    FAISS_INDEX_PATH = "data/vector_store/index.faiss"
    ```
- Chuá»—i truy há»“i má»›i:
  1. **FAISS (dense)** láº¥y top-k rá»™ng â†’
  2. **BM25 (sparse)** bá»• sung phá»§ chá»‰ má»¥c â†’
  3. **Cross-Encoder reranker** sáº¯p xáº¿p láº¡i theo má»©c Ä‘á»™ liÃªn quan â†’
  4. **Chá»n TOP_K_FINAL** cho LLM.
- Chuáº©n hÃ³a logging: dÃ¹ng `default_logger` (thay vÃ¬ `logger` ráº£i rÃ¡c) Ä‘á»ƒ thá»‘ng nháº¥t Ä‘áº§u ra.

## ğŸ¤– LLM Orchestration

- **Tá»± Ä‘á»™ng chá»n model Gemini** kháº£ dá»¥ng (Æ°u tiÃªn dÃ²ng 2.5) vÃ  **fallback** náº¿u model/safety khÃ´ng tÆ°Æ¡ng thÃ­ch.
- **Retry chiáº¿n lÆ°á»£c**:
  - Thá»­ vá»›i `safety_settings` typed; náº¿u lá»—i â†’ chuyá»ƒn sang dict; náº¿u váº«n lá»—i â†’ táº¡m **táº¯t safety** (trong pháº¡m vi an toÃ n) vÃ  retry láº§n cuá»‘i.
- **Prompting** giá»¯ nguyÃªn cáº¥u trÃºc RAG nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n vá»›i rerank Ä‘áº§u vÃ o.

## ğŸ§  Vector hÃ³a & Chá»‰ má»¥c

- Chuyá»ƒn embedding tá»« `all-MiniLM-L6-v2` â†’ **`BAAI/bge-m3`** (Ä‘a ngÃ´n ngá»¯, cáº£i thiá»‡n tiáº¿ng Viá»‡t).
- Chuáº©n hÃ³a **FAISS index** (file `.faiss`) + metadata kÃ¨m id Ä‘á»ƒ truy váº¿t nguá»“n.
- Giá»¯ kháº£ nÄƒng **migrate** tá»« vector `.pkl` cÅ© (Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng thÃ­ch trong config).

## ğŸ” Truy há»“i lai (Hybrid Retrieval)

- **Káº¿t há»£p Ä‘iá»ƒm**: `score = Î± * dense + (1-Î±) * BM25` vá»›i `HYBRID_ALPHA = 0.60`.
- **Rerank báº±ng Cross-Encoder** sau há»£p nháº¥t Ä‘á»ƒ lá»c nhiá»…u vÃ  Ä‘áº©y cÃ¡c Ä‘oáº¡n â€œÄ‘Ãºng cÃ¢u há»iâ€ lÃªn Ä‘áº§u.
- **KeywordExtractor** giÃºp á»•n Ä‘á»‹nh truy há»“i vá»›i cÃ¢u há»i ngáº¯n/gÃ£y.

## ğŸ“¦ Phá»¥ thuá»™c & mÃ´i trÆ°á»ng

- `requirements.txt` bá»• sung:
  - `faiss-cpu` â€” chá»‰ má»¥c & tÃ¬m kiáº¿m vector nhanh.
  - `rank-bm25` â€” BM25 sparse retrieval.
  - (Giá»¯ `sentence_transformers`, `google.generativeai`, â€¦)

## ğŸ“Š Hiá»‡u suáº¥t & Cháº¥t lÆ°á»£ng (tÃ¡c Ä‘á»™ng ká»³ vá»ng)

- **Äá»™ chÃ­nh xÃ¡c**:
  - Dense tá»‘t tiáº¿ng Viá»‡t (BGE-M3) + **BM25 bá»• khuyáº¿t tá»« khÃ³a** + **Cross-Encoder rerank** â‡’ tÄƒng **precision@k** vÃ  cháº¥t lÆ°á»£ng trÃ­ch dáº«n.
- **Äá»™ bao phá»§**:
  - `TOP_K_RECALL = 50` trÆ°á»›c rerank giÃºp **khÃ´ng bá» sÃ³t** Ä‘oáº¡n liÃªn quan (nháº¥t lÃ  mÃ´ táº£ há»c pháº§n/danh má»¥c CTÄT dÃ i).
- **Tá»‘c Ä‘á»™**:
  - **FAISS** thay vÃ¬ thuáº§n cosine + NumPy â‡’ truy váº¥n dense nhanh vÃ  á»•n Ä‘á»‹nh á»Ÿ quy mÃ´ lá»›n.
  - Chu trÃ¬nh **reindex** riÃªng (`reindex_faiss.py`) rÃºt ngáº¯n thá»i gian build/rebuild chá»‰ má»¥c.

---

### TÃ³m táº¯t nhanh

**Hybrid (FAISS + BM25 + Rerank)**, **BGE-M3**, tham sá»‘ truy há»“i rÃµ rÃ ng, **LLM Gemini** cÃ³ **retry + safety fallback**, chá»‰ má»¥c FAISS, script reindex, logging thá»‘ng nháº¥t.

## How to run

```bash
# 1) Environment
python -m venv .venv
# Windows PowerShell: .\.venv\Scripts\Activate.ps1
# Linux/Mac: source .venv/bin/activate
pip install -U pip
pip install sentence-transformers faiss-cpu rank-bm25 google-generativeai python-dotenv pymupdf4llm

# 2) Config .env
# .env
# GEMINI_API_KEY=YOUR_KEY
# (optional) GEMINI_MODEL_NAME=models/gemini-2.5-flash
# (optional) MAX_CONTEXT_CHARS=12000
# (optional) SHOW_DEBUG=1

# 3) Build index
python main.py

# 4) Ask questions about the curriculum (CLI)
python qa_interface.py
```
