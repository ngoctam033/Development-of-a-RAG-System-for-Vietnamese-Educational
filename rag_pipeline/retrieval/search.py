from typing import List, Dict, Any
import numpy as np
import faiss
from utils.logger import logger

def search_similar(
    query_text: str,
    store: Dict[str, Any],
    top_k: int = 3,
    header_path_filter: List[str] = None
) -> List[Dict[str, Any]]:
    """
    Find documents similar to the query text using FAISS, with optional header_path filtering.
    """
    model = store["embedding_model"]
    faiss_index = store["faiss_index"]
    vectorized_data = store["vectorized_data"]

    # Náº¿u cÃ³ header_path_filter, lá»c trÆ°á»›c vectorized_data
    if header_path_filter is not None:
        # logger.info(f"ğŸ” Äang lá»c vector theo header_path_filter: {header_path_filter}")
        vectorized_data = filter_vectors_by_metadata(
            vectorized_data,
            {"header_path": header_path_filter}
        )
        # logger.info(f"âœ… Sá»‘ vector sau khi lá»c: {len(vectorized_data)}")
        # Náº¿u lá»c xong, cáº§n build láº¡i faiss_index cho táº­p nÃ y
        embeddings = np.array([item["embedding"] for item in vectorized_data]).astype('float32')
        if len(embeddings) > 0:
            faiss_index = faiss.IndexFlatIP(embeddings.shape[1])
            faiss.normalize_L2(embeddings)
            faiss_index.add(embeddings)
            logger.info(f"âœ… ÄÃ£ build láº¡i FAISS index cho táº­p vector Ä‘Ã£ lá»c")
        else:
            logger.warning("âš ï¸ KhÃ´ng cÃ²n vector nÃ o sau khi lá»c, tráº£ vá» rá»—ng.")
            return []

    logger.info(f"ğŸ” Äang mÃ£ hÃ³a query vÃ  tÃ¬m kiáº¿m tÆ°Æ¡ng Ä‘á»“ng FAISS cho: '{query_text}'")
    query_embedding = model.encode(query_text)
    query_embedding = np.array(query_embedding, dtype='float32').reshape(1, -1)
    faiss.normalize_L2(query_embedding)

    scores, indices = faiss_index.search(query_embedding, top_k)
    logger.info(f"âœ… ÄÃ£ tÃ¬m kiáº¿m xong, tráº£ vá» top {top_k} káº¿t quáº£.")
    results = []
    for i, idx in enumerate(indices[0]):
        if idx >= len(vectorized_data):
            continue
        doc = vectorized_data[idx]
        results.append({
            "content": doc["content"],
            "metadata": doc["metadata"],
            "similarity_score": float(scores[0][i])
        })
        if len(results) >= top_k:
            break
    logger.info(f"âœ… Sá»‘ káº¿t quáº£ tráº£ vá»: {len(results)}")
    return results

def filter_vectors_by_metadata(vectorized_data: List[Dict[str, Any]], metadata_filter: dict) -> List[Dict[str, Any]]:
    """
    Lá»c cÃ¡c vector theo Ä‘iá»u kiá»‡n metadata_filter nÃ¢ng cao.
    Náº¿u value lÃ  str, kiá»ƒm tra chuá»—i con; náº¿u khÃ´ng, so sÃ¡nh báº±ng tuyá»‡t Ä‘á»‘i.
    """
    # logger.info(f"ğŸ” Báº¯t Ä‘áº§u lá»c vector vá»›i metadata_filter: {metadata_filter}")
    filtered = []
    for item in vectorized_data:
        # logger.info(f"Checking item with metadata: {item['metadata']}")
        meta = item["metadata"]
        match = True
        for k, v in metadata_filter.items():
            meta_value = meta.get(k)
            # logger.info(f"Comparing metadata key '{k}': filter value '{v}' with item value '{meta_value}'")
            if isinstance(v, list):
                # Náº¿u v lÃ  list, kiá»ƒm tra meta_value cÃ³ náº±m trong list v
                if meta_value not in v:
                    match = False
                    break
            elif isinstance(v, str) and isinstance(meta_value, str):
                # Náº¿u v lÃ  string, kiá»ƒm tra chuá»—i con
                if v not in meta_value:
                    match = False
                    break
            else:
                # So sÃ¡nh tuyá»‡t Ä‘á»‘i
                if meta_value != v:
                    match = False
                    break
        if match:
            filtered.append(item)
    logger.info(f"âœ… ÄÃ£ lá»c xong, cÃ²n láº¡i {len(filtered)} vector.")
    return filtered